{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"AstS2QF9SN4L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675337892997,"user_tz":-60,"elapsed":22167,"user":{"displayName":"DANIELE SILVITELLI","userId":"06101420645295177517"}},"outputId":"48ee8ab4-ef1e-4111-b85b-aad7b62da534"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eXKbFIh2SZ4X"},"outputs":[],"source":["import os\n","os.chdir('/content/drive/My Drive/Tesi')"]},{"cell_type":"code","source":["import cv2\n","import math\n","import copy\n","import random\n","import pickle\n","import numpy as np\n","import pandas as pd\n","from tensorflow import keras\n","from collections import deque\n","from keras.utils import Sequence\n","import matplotlib.pyplot as plt\n","from sklearn.utils import shuffle\n","from keras.models import load_model\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"4lfaOnjgih_B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sequence_length = 4\n","sequence_stride = 2\n","batch_size      = 16"],"metadata":{"id":"lZN5GiZ0tVLy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Split of the dataset using 5Fold-CrossValidation technique"],"metadata":{"id":"AmpZY0bVZ0e4"}},{"cell_type":"code","source":["# creating a dataframe with all video names\n","\n","csv = pd.read_csv('csv/wild_long-range_annotation.csv')\n","\n","dict_videos = {'Name video': []}\n","\n","prev_video = ''\n","\n","for index, row in csv.iterrows():\n","  # finding DATASET NAME from csv 'filename'\n","  idx_of_start_dataset_name = 54 # for short-range this number is 55, for urban short-range this number is 56\n","  row_substring_dataset = row['filename'][idx_of_start_dataset_name:] \n","  idx_of_end_dataset_name = idx_of_start_dataset_name + row_substring_dataset.index('/')\n","  dataset_name = row['filename'][idx_of_start_dataset_name:idx_of_end_dataset_name]\n","  # finding VIDEO NAME from csv 'filename'\n","  idx_of_start_video_name = idx_of_end_dataset_name + 17\n","  row_substring_video = row['filename'][idx_of_start_video_name:]\n","  idx_of_end_video_name = idx_of_start_video_name + row_substring_video.index('/')\n","  video_name = row['filename'][idx_of_start_video_name:idx_of_end_video_name]\n","  \n","  if (video_name != prev_video):\n","    dict_videos['Name video'].append(video_name)\n","    prev_video = video_name\n","\n","# dict_videos['Name video'].append(prev_video)\n","\n","df_videos = pd.DataFrame.from_dict(dict_videos)\n","print(df_videos)"],"metadata":{"id":"2WqNnB-qEvit"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","\n","kf = KFold(n_splits=5, shuffle=True)\n","\n","subdivisions = []\n","for train_indexes, test_indexes in kf.split(df_videos):\n","  subdivisions.append([train_indexes, test_indexes])\n","\n","train_videos = []\n","test_videos = []\n","val_videos = []\n","\n","for single_subdivision in subdivisions:\n","  train_indexes = single_subdivision[0]\n","  test_indexes = single_subdivision[1]\n","  val_videos.append(df_videos.iloc[train_indexes[:40]])\n","  train_videos.append(df_videos.iloc[train_indexes[40:]])\n","  test_videos.append(df_videos.iloc[test_indexes])"],"metadata":{"id":"uwQNPQlrDGJU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TRAIN\n","for i in range(0, 5):\n","  for index_i, row_i in train_videos[i].iterrows():\n","    dict_train = {'filename':[], 'Flames':[]}       # CREATE A NEW CSV FOR EACH VIDEO\n","    for index_j, row_j in starting_csv.iterrows():\n","      if '/' + row_i['Name video'] + '/' in row_j['filename']:\n","        dict_train['filename'].append('/user/dsilvitelli/kerasenv/bin' + row_j['filename'][23:])\n","        dict_train['Flames'].append(row_j['Flames'])\n","    df_train = pd.DataFrame.from_dict(dict_train)\n","    df_train.to_csv('csv/Train/wild/KFold_long-range/fold' + str(i+1) + '/' + row_i['Name video'] + '.csv')\n","\n","# TEST\n","for i in range(0, 5):\n","  for index_i, row_i in test_videos[i].iterrows():\n","    dict_test = {'filename':[], 'Flames':[]}       # CREATE A NEW CSV FOR EACH VIDEO\n","    for index_j, row_j in starting_csv.iterrows():\n","      if '/' + row_i['Name video'] + '/' in row_j['filename']:\n","        dict_test['filename'].append('/user/dsilvitelli/kerasenv/bin' + row_j['filename'][23:])\n","        dict_test['Flames'].append(row_j['Flames'])\n","    df_test = pd.DataFrame.from_dict(dict_test)\n","    df_test.to_csv('csv/Test/wild/KFold_long-range/fold' + str(i+1) + '/' + row_i['Name video'] + '.csv')\n","\n","# VAL\n","for i in range(0, 5):\n","  for index_i, row_i in val_videos[i].iterrows():\n","    dict_val = {'filename':[], 'Flames':[]}       # CREATE A NEW CSV FOR EACH VIDEO\n","    for index_j, row_j in starting_csv.iterrows():\n","      if '/' + row_i['Name video'] + '/' in row_j['filename']:\n","        dict_val['filename'].append('/user/dsilvitelli/kerasenv/bin' + row_j['filename'][23:])\n","        dict_val['Flames'].append(row_j['Flames'])\n","    df_val = pd.DataFrame.from_dict(dict_val)\n","    df_val.to_csv('csv/Validation/wild/KFold_long-range/fold' + str(i+1) + '/' + row_i['Name video'] + '.csv')"],"metadata":{"id":"M-AqlyyfK9yM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check subdivisions\n","to_check_test = []\n","to_check_train = []\n","for i in range(0, 5):\n","  data_path = os.path.join('csv', 'Test/wild/KFold_long-range/fold' + str(i+1))\n","  data_files = os.listdir(data_path)\n","  to_check_test.append(data_files)\n","for i in range(0, 5):\n","  data_path = os.path.join('csv', 'Train/wild/KFold_long-range/fold' + str(i+1))\n","  data_files = os.listdir(data_path)\n","  to_check_train.append(data_files)"],"metadata":{"id":"CXYBTLRQJbHG"},"execution_count":null,"outputs":[]}]}