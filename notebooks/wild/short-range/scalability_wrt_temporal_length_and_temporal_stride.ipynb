{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"AstS2QF9SN4L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678788729028,"user_tz":-60,"elapsed":24104,"user":{"displayName":"DANIELE SILVITELLI","userId":"06101420645295177517"}},"outputId":"5943125b-1c47-47db-ba19-a27e2d4eea4e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eXKbFIh2SZ4X"},"outputs":[],"source":["import os\n","os.chdir('/content/drive/My Drive/Tesi')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4lfaOnjgih_B"},"outputs":[],"source":["import cv2\n","import math\n","import copy\n","import random\n","import numpy as np\n","import pandas as pd\n","from tensorflow import keras\n","from collections import deque\n","import matplotlib.pyplot as plt\n","from sklearn.utils import shuffle\n","from keras.models import load_model\n","from tensorflow.keras.utils import Sequence\n","\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","source":["sequence_length = 8\n","sequence_stride = 4\n","batch_size      = 16"],"metadata":{"id":"w-zgb7iW5rb3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Creation of the model with new temporal length and temporal stride"],"metadata":{"id":"hD4uDFbFjFF0"}},{"cell_type":"code","source":["from keras import Model\n","from keras.layers import TimeDistributed, Input\n","\n","mnv2 = load_model('notebooks/wild/short-range/MobileNetV2/case9/case9_best_model3.h5')\n","\n","input_layer = Input(shape=(sequence_length, 224, 224, 3))\n","x = TimeDistributed(mnv2.layers[1].layer)(input_layer)\n","x = mnv2.layers[2](x)\n","x = mnv2.layers[3](x)\n","x = mnv2.layers[4](x)\n","\n","new_model = Model(inputs=input_layer, outputs=x)\n","new_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YHgbLLiToS9b","executionInfo":{"status":"ok","timestamp":1678788747668,"user_tz":-60,"elapsed":7964,"user":{"displayName":"DANIELE SILVITELLI","userId":"06101420645295177517"}},"outputId":"7e8785ea-b2f6-4bb2-a6fb-b4d8f74de129"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 8, 224, 224, 3)]  0         \n","                                                                 \n"," time_distributed (TimeDistr  (None, 8, 1280)          2257984   \n"," ibuted)                                                         \n","                                                                 \n"," lstm (LSTM)                 (None, 100)               552400    \n","                                                                 \n"," dropout (Dropout)           (None, 100)               0         \n","                                                                 \n"," dense (Dense)               (None, 1)                 101       \n","                                                                 \n","=================================================================\n","Total params: 2,810,485\n","Trainable params: 2,776,373\n","Non-trainable params: 34,112\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["# Train the model with new temporal length and temporal stride"],"metadata":{"id":"RKidESlOdoGe"}},{"cell_type":"code","source":["def file_generator(data_path, data_files, temporal_stride, temporal_length):\n","  '''\n","  data_files - list of csv files to be read\n","  '''\n","  for f in data_files:\n","    tmp_df = pd.read_csv(os.path.join(data_path, f))\n","    total_images = len(tmp_df)\n","    if total_images >= temporal_length:\n","      num_samples = int((total_images - temporal_length)/temporal_stride) + 1\n","      # print('num of samples from vid seq-{}: {}'.format(f, num_samples))\n","    else:\n","      # print('num of frames is less than temporal length; hence discarding this \\\n","      #       file-{}'.format(f))\n","      continue\n","\n","    samples = deque()\n","    labels = deque()\n","\n","    for index, row in tmp_df.iterrows():\n","      samples.append('/content/drive/My Drive' + row['filename'][30:])\n","      labels.append(int(row['Flames']))\n","      if len(samples) == temporal_length:\n","        to_delete = False\n","        if labels.count(labels[0]) != len(labels):\n","          to_delete = True\n","        samples_c = copy.deepcopy(samples)\n","        for t in range(temporal_stride):\n","          samples.popleft()\n","          labels.popleft()\n","        if to_delete: continue\n","        yield samples_c, labels[0]\n","\n","def load_samples(CSV_folder, temporal_stride, temporal_length):\n","  data_path = os.path.join('csv', CSV_folder)\n","  data_files = os.listdir(data_path)\n","  file_gen = file_generator(data_path, data_files, temporal_stride, temporal_length)\n","  iterator = True\n","  data_list = []\n","\n","  while iterator:\n","    try:\n","      x, y = next(file_gen)\n","      x = list(x)\n","      data_list.append([x, y])\n","    except Exception as e:\n","      # print('Exception: ', e)\n","      iterator = False\n","      # print('end of data generator ')\n","  return data_list\n","\n","def to_weight(train_data):\n","  # putting generated labels into a list\n","  training_labels = []\n","  for sample in range(len(train_data)):\n","    training_labels.append(train_data[sample][1])\n","\n","  weights_sklearn = compute_class_weight(class_weight='balanced', \n","                                        classes=np.unique(np.array(training_labels)),\n","                                        y=np.array(training_labels))\n","  weights = {0: weights_sklearn[0], 1: weights_sklearn[1]}\n","  return weights\n","\n","class DataGenerator(Sequence):\n","\n","    def __init__(self, data, batch_size, shuffle_data, aug):\n","        self.num_samples = len(data)\n","        self.data = shuffle(data) if shuffle_data else data\n","        self.batch_size = batch_size\n","        self.aug = aug        \n","        self.additional_targets = {[f'image{i}' for i in range(sequence_length-1)][j]:'image' for j in range(sequence_length-1)}\n","\n","    def __len__(self):\n","        return math.ceil(len(self.data) / self.batch_size)\n","\n","    def __getitem__(self, idx):\n","        #print('starting index: ', idx * self.batch_size)\n","        batch_samples = self.data[idx * self.batch_size:(idx + 1) * self.batch_size]\n","        X_train = []\n","        y_train = []\n","        for batch_sample in batch_samples:\n","            x = batch_sample[0]   # Load image (X)\n","            y = batch_sample[1]   # Read label (y)\n","            temp_data_list = []\n","            for img_name in x:\n","                try:\n","                    img = cv2.imread(img_name)\n","                    img = cv2.resize(img, (224,224))\n","                    temp_data_list.append(img[:,:, ::-1])\n","                except Exception as e:\n","                    print(e)\n","                    print('error reading file: ', img_name)\n","            if self.aug:\n","                temp_data_list = self.__totransform__(temp_data_list)\n","            # Add example to arrays\n","            X_train.append(temp_data_list)\n","            y_train.append(y)\n","        # Make sure they're numpy arrays (as opposed to lists)\n","        X_train = np.array(X_train)\n","        y_train = np.array(y_train)\n","        return X_train, y_train\n","   \n","    def __totransform__(self, list_of_frames):\n","\n","        transform = A.Compose([   \n","            A.HorizontalFlip(p=0.5),\n","            A.OneOf(\n","              [\n","                A.Blur(p=0.01, blur_limit=(3, 7)),\n","                A.MedianBlur(p=0.01, blur_limit=(3, 7)),\n","                A.MotionBlur(p=0.01, blur_limit=(3, 7)),\n","                A.GaussianBlur(p=0.01, blur_limit=(3, 7), sigma_limit=(0.0, 0)),\n","                #A.ZoomBlur(p=0.01, max_factor=(1.0, 1.12), step_factor=(0.01, 0.03)),\n","                #A.Defocus(p=0.01, radius=(1, 4), alias_blur=(0.1, 0.5)),\n","                A.RingingOvershoot(p=0.01, blur_limit=(7, 15), cutoff=(0.7, 1.57)),\n","                A.Downscale(p=0.01, scale_min=0.8, scale_max=0.99),\n","                A.ImageCompression(p=0.01, quality_lower=80, quality_upper=100,\n","                                    compression_type=0),\n","                A.JpegCompression(p=0.01, quality_lower=80, quality_upper=100),\n","                A.GaussNoise(p=0.01, var_limit=(10, 50), per_channel=True, mean=0.0),\n","                A.MultiplicativeNoise(p=0.01, multiplier=(0.9, 1.1), \n","                                        per_channel=True, elementwise=True),\n","                # A.CLAHE(p=0.01, clip_limit=(1,4), tile_grid_size=(8, 8)),\n","                # A.Sharpen(p=0.01, alpha=(0.2, 0.5), lightness=(0.5, 1.0)),\n","                # A.UnsharpMask(p=0.01, blur_limit=(3, 7), sigma_limit=(0.0, 0.0),\n","                #                 alpha=(0.2, 0.5), threshold=10),\n","                # A.Emboss(p=0.01, alpha=(0.2, 0.5), strength=(0.2, 0.7)),\n","                # A.RandomBrightness(p=0.01, limit=(-0.2, 0.2)),\n","                # A.RandomContrast(p=0.01, limit=(-0.2, 0.2)),\n","                # A.RandomBrightnessContrast(p=0.01, brightness_limit=(-0.2, 0.2),\n","                #                             contrast_limit=(-0.2, 0.2), \n","                #                             brightness_by_max=True),\n","                # A.ISONoise(p=0.01, intensity=(0.1, 0.5), color_shift=(0.01, 0.05)),\n","                # A.Equalize(p=0.01, mode='cv', by_channels=False),             \n","                # A.FancyPCA(p=0.01, alpha=0.1),\n","                # A.RGBShift(p=0.01, r_shift_limit=(-20, 20), \n","                #             g_shift_limit=(-20, 20), b_shift_limit=(-20, 20)),\n","                # A.RandomGamma(p=0.01, gamma_limit=(80, 120), eps=None),\n","                # A.RandomToneCurve(p=0.01, scale=0.1),\n","                # A.SafeRotate(p=0.01, limit=(-90, 90), interpolation=0, \n","                #               border_mode=0, value=(0, 0, 0), mask_value=None),\n","                # A.OpticalDistortion(p=0.01, distort_limit=(-0.3, 0.3),\n","                #                       shift_limit=(-0.05, 0.05), interpolation=0,\n","                #                       border_mode=0, value=(0, 0, 0), mask_value=None),\n","                # A.GridDistortion(p=0.01, num_steps=5, distort_limit=(-0.3, 0.3),\n","                #                   interpolation=0, border_mode=0, value=(0, 0, 0),\n","                #                   mask_value=None, normalized=False),\n","                # A.Perspective(p=0.01, scale=(0.05, 0.1), keep_size=0, pad_mode=0,\n","                #                 pad_val=(0, 0, 0), mask_pad_val=0, fit_output=0, \n","                #                 interpolation=0),\n","                # A.PiecewiseAffine(p=0.01, scale=(0.03, 0.05), nb_rows=(4, 4), \n","                #                     nb_cols=(4, 4), interpolation=0,\n","                #                     mask_interpolation=0, cval=0, cval_mask=0,\n","                #                     mode='constant', absolute_scale=0, \n","                #                     keypoints_threshold=0.01),\n","                # A.RandomCropFromBorders(p=0.01, crop_left=0.1, crop_right=0.1, \n","                #                           crop_top=0.1, crop_bottom=0.1),\n","                # A.CoarseDropout(p=0.01, max_holes=8, max_height=8, max_width=8, \n","                #                   min_holes=8, min_height=8, min_width=8, \n","                #                   fill_value=(0, 0, 0), mask_fill_value=None),\n","                # A.PixelDropout(p=0.01, dropout_prob=0.01, per_channel=0, \n","                #                 drop_value=(0, 0, 0), mask_drop_value=None),\n","                # A.RandomFog(p=0.01, fog_coef_lower=0.2, fog_coef_upper=0.2, \n","                #               alpha_coef=0.08),\n","                # A.RandomSnow(p=0.01, snow_point_lower=0.1, snow_point_upper=0.1, \n","                #               brightness_coeff=2),\n","                # A.RandomRain(p=0.01, slant_lower=-10, slant_upper=10, \n","                #               drop_length=20, drop_width=1, drop_color=(0, 0, 0),\n","                #               blur_value=3, brightness_coefficient=0.7, rain_type=None),\n","                # A.Spatter(p=0.01, mean=(0.65, 0.65), std=(0.3, 0.3), \n","                #             gauss_sigma=(2.0, 2.0), intensity=(0.6, 0.6), \n","                #             cutout_threshold=(0.68, 0.68), mode=['rain']),\n","                # A.Spatter(p=0.01, mean=(0.65, 0.65), std=(0.3, 0.3), \n","                #             gauss_sigma=(2.0, 2.0), intensity=(0.6, 0.6), \n","                #             cutout_threshold=(0.68, 0.68), mode=['mud']),\n","              ], p=0.8),\n","        ], additional_targets=self.additional_targets)\n","\n","        transformed = transform(image=list_of_frames[0], \n","                                image0=list_of_frames[1], \n","                                image1=list_of_frames[2],\n","                                image2=list_of_frames[3],\n","                                image3=list_of_frames[4],\n","                                image4=list_of_frames[5],\n","                                image5=list_of_frames[6],\n","                                image6=list_of_frames[7]  )\n","        \n","        return  [   cv2.resize(transformed['image'], (224,224)),\n","                    cv2.resize(transformed['image0'], (224,224)),\n","                    cv2.resize(transformed['image1'], (224,224)),\n","                    cv2.resize(transformed['image2'], (224,224)),\n","                    cv2.resize(transformed['image3'], (224,224)),\n","                    cv2.resize(transformed['image4'], (224,224)),\n","                    cv2.resize(transformed['image5'], (224,224)),\n","                    cv2.resize(transformed['image6'], (224,224))   ]\n","\n","fit_results = []\n","evaluate_results = []\n","\n","for count in range(1, 6):\n","    train_data = load_samples(CSV_folder='Train/wild/KFold_short-range/fold'\\\n","                                + str(count), temporal_stride=sequence_stride,\n","                            temporal_length=sequence_length)\n","    test_data = load_samples(CSV_folder='Test/wild/KFold_short-range/fold'\\\n","                            + str(count), temporal_stride=sequence_stride,\n","                            temporal_length=sequence_length)\n","    val_data = load_samples(CSV_folder='Validation/wild/KFold_short-range/fold'\\\n","                           + str(count), temporal_stride=sequence_stride,\n","                          temporal_length=sequence_length)\n","    \n","    weights = to_weight(train_data)\n","\n","    train_gen = DataGenerator(data=train_data, batch_size=batch_size, \n","                                shuffle_data=True, aug=True)\n","    test_gen = DataGenerator(data=test_data, batch_size=batch_size, \n","                            shuffle_data=False, aug=False)\n","    val_gen = DataGenerator(data=val_data, batch_size=batch_size, \n","                            shuffle_data=True, aug=False)\n","\n","    model = new_model\n","    model.compile(loss='binary_crossentropy',\n","                    optimizer=SGD(), metrics=['accuracy'])\n","    \n","    cs = 'case9_seq8'\n","    \n","    my_callbacks = [\n","        keras.callbacks.EarlyStopping(monitor='val_loss', verbose=1, patience=5,\n","                                    mode='auto', restore_best_weights=True),\n","        keras.callbacks.ModelCheckpoint(\n","            'models/wild/short-range/MobileNetV2/new_sequence_lengths/8temporal_length_4temporalstride/' + cs + '_best_model' + str(count) + '.h5',\n","            monitor='val_loss', verbose=1, save_best_only=True, mode='auto'),\n","        keras.callbacks.TensorBoard(log_dir='models/wild/short-range/MobileNetV2/new_sequence_lengths/8temporal_length_4temporalstride/' + cs + '_tensorboard' + str(count)),\n","        keras.callbacks.CSVLogger(\n","            'models/wild/short-range/MobileNetV2/new_sequence_lengths/8temporal_length_4temporalstride/' + cs + '_epochs_results' + str(count) + '.csv',\n","            separator=\",\", append=False),\n","    ]\n","\n","    print(\"\\n\\n\" + cs + \" - STARTING FIT \" + str(count) + \" ...\\n\\n\")\n","\n","    model.fit(train_gen, epochs=50, validation_data=val_gen, callbacks=my_callbacks,\n","            class_weight=weights, use_multiprocessing=True, workers=4)"],"metadata":{"id":"Ae2sQp28q-QP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FcrO3QbOvdYP"},"source":["# Evaluate model with different sequence length"]},{"cell_type":"code","source":["import os\n","import cv2\n","import math\n","import copy\n","import random\n","import numpy as np\n","import pandas as pd\n","from tensorflow import keras\n","from collections import deque\n","import matplotlib.pyplot as plt\n","from sklearn.utils import shuffle\n","from keras.models import load_model\n","from tensorflow.keras.utils import Sequence\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","\n","\n","sequence_length = 8\n","sequence_stride = 4\n","batch_size      = 16\n","\n","def file_generator(data_path, data_files, temporal_stride, temporal_length):\n","  '''\n","  data_files - list of csv files to be read\n","  '''\n","  for f in data_files:\n","    tmp_df = pd.read_csv(os.path.join(data_path, f))\n","    total_images = len(tmp_df)\n","    if total_images >= temporal_length:\n","      num_samples = int((total_images - temporal_length)/temporal_stride) + 1\n","      #print('num of samples from vid seq-{}: {}'.format(f, num_samples))\n","    else:\n","      #print('num of frames is less than temporal length; hence discarding this \\\n","      #      file-{}'.format(f))\n","      continue\n","\n","    samples = deque()\n","    labels = deque()\n","\n","    for index, row in tmp_df.iterrows():\n","      samples.append('/content/drive/My Drive' + row['filename'][30:])\n","      labels.append(int(row['Flames']))\n","      if len(samples) == temporal_length:\n","        to_delete = False\n","        if labels.count(labels[0]) != len(labels):\n","          to_delete = True\n","        samples_c = copy.deepcopy(samples)\n","        for t in range(temporal_stride):\n","          samples.popleft()\n","          labels.popleft()\n","        if to_delete: continue\n","        yield samples_c, labels[0]\n","\n","def load_samples(CSV_folder, temporal_stride, temporal_length):\n","  data_path = os.path.join('csv', CSV_folder)\n","  data_files = os.listdir(data_path)\n","  file_gen = file_generator(data_path, data_files, temporal_stride, temporal_length)\n","  iterator = True\n","  data_list = []\n","\n","  while iterator:\n","    try:\n","      x, y = next(file_gen)\n","      x = list(x)\n","      data_list.append([x, y])\n","    except Exception as e:\n","      #print('Exception: ', e)\n","      iterator = False\n","      #print('end of data generator ')\n","  return data_list\n","\n","class DataGenerator(Sequence):\n","\n","    def __init__(self, data, batch_size, shuffle_data, aug):\n","        self.num_samples = len(data)\n","        self.data = shuffle(data) if shuffle_data else data\n","        self.batch_size = batch_size\n","        self.aug = aug        \n","        self.additional_targets = {[f'image{i}' for i in range(sequence_length-1)][j]:'image' for j in range(sequence_length-1)}\n","\n","    def __len__(self):\n","        return math.ceil(len(self.data) / self.batch_size)\n","\n","    def __getitem__(self, idx):\n","        #print('starting index: ', idx * self.batch_size)\n","        batch_samples = self.data[idx * self.batch_size:(idx + 1) * self.batch_size]\n","        X_train = []\n","        y_train = []\n","        for batch_sample in batch_samples:\n","            x = batch_sample[0]   # Load image (X)\n","            y = batch_sample[1]   # Read label (y)\n","            temp_data_list = []\n","            for img_name in x:\n","                try:\n","                    img = cv2.imread(img_name)\n","                    img = cv2.resize(img, (224,224))\n","                    temp_data_list.append(img[:,:, ::-1])\n","                except Exception as e:\n","                    print(e)\n","                    print('error reading file: ', img_name)\n","            # if self.aug:\n","            #     temp_data_list = self.__totransform__(temp_data_list)\n","            # Add example to arrays\n","            X_train.append(temp_data_list)\n","            y_train.append(y)\n","        # Make sure they're numpy arrays (as opposed to lists)\n","        X_train = np.array(X_train)\n","        y_train = np.array(y_train)\n","        return X_train, y_train\n","\n","test_data = load_samples(CSV_folder='Test/wild/KFold_short-range/fold3', \n","                            temporal_stride=sequence_stride,\n","                            temporal_length=sequence_length)\n","\n","test_gen = DataGenerator(data=test_data, batch_size=batch_size, \n","                         shuffle_data=False, aug=False)\n","\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","\n","def plot_cm(y, pred):\n","  p = []\n","  for i in pred:\n","    p.append(round(list(i)[0]))\n","  p = np.array(p)\n","  y = np.array(y)\n","  cm = confusion_matrix(y, p)\n","  disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n","  print('Accuracy: %.3f' % (y==p).mean())\n","  disp.plot()\n","  plt.title('Accuracy: %.3f' % (y==p).mean())\n","  plt.show()\n","\n","model = load_model('models/wild/short-range/MobileNetV2/new_sequence_lengths/8temporal_length_4temporalstride/case9_seq8_best_model3.h5')\n","\n","test_labels = []\n","for test in range(len(test_data)):\n","  test_labels.append(test_data[test][1])\n","\n","pred = model.predict(test_gen)\n","plot_cm(y=test_labels, pred=list(pred))"],"metadata":{"id":"s41dZrDVFIH_"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":["hD4uDFbFjFF0","RKidESlOdoGe","FcrO3QbOvdYP"],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}