{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"AstS2QF9SN4L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678788526784,"user_tz":-60,"elapsed":23132,"user":{"displayName":"DANIELE SILVITELLI","userId":"06101420645295177517"}},"outputId":"7f8453fb-36b6-441b-8aae-146f2d29001e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eXKbFIh2SZ4X"},"outputs":[],"source":["import os\n","os.chdir('/content/drive/My Drive/Tesi')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4lfaOnjgih_B"},"outputs":[],"source":["import cv2\n","import math\n","import copy\n","import random\n","import numpy as np\n","import pandas as pd\n","from tensorflow import keras\n","from collections import deque\n","import matplotlib.pyplot as plt\n","from sklearn.utils import shuffle\n","from keras.models import load_model\n","from tensorflow.keras.utils import Sequence\n","\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","source":["sequence_length = 8\n","sequence_stride = 4\n","batch_size      = 16"],"metadata":{"id":"w-zgb7iW5rb3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Creation of the model with new temporal length and temporal stride"],"metadata":{"id":"JARIZwZx-a7X"}},{"cell_type":"code","source":["from keras import Model\n","from keras.layers import TimeDistributed, Input\n","\n","mnv2 = load_model('models/urban/long-range/EfficientDet/case8/case8_best_model2.h5')\n","\n","input_layer = Input(shape=(sequence_length, 224, 224, 3))\n","x = TimeDistributed(mnv2.layers[1].layer)(input_layer)\n","x = mnv2.layers[2](x)\n","x = mnv2.layers[3](x)\n","x = mnv2.layers[4](x)\n","\n","new_model = Model(inputs=input_layer, outputs=x)\n","new_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YHgbLLiToS9b","executionInfo":{"status":"ok","timestamp":1678788620290,"user_tz":-60,"elapsed":10187,"user":{"displayName":"DANIELE SILVITELLI","userId":"06101420645295177517"}},"outputId":"58c0e2bc-b771-4d4c-8ede-26ca7d0c2111"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 8, 224, 224, 3)]  0         \n","                                                                 \n"," time_distributed_1 (TimeDis  (None, 8, 1280)          4049571   \n"," tributed)                                                       \n","                                                                 \n"," lstm (LSTM)                 (None, 100)               552400    \n","                                                                 \n"," dropout (Dropout)           (None, 100)               0         \n","                                                                 \n"," dense (Dense)               (None, 1)                 101       \n","                                                                 \n","=================================================================\n","Total params: 4,602,072\n","Trainable params: 4,560,049\n","Non-trainable params: 42,023\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["# Train the model with new temporal length and temporal stride"],"metadata":{"id":"RKidESlOdoGe"}},{"cell_type":"code","source":["def file_generator(data_path, data_files, temporal_stride, temporal_length):\n","  '''\n","  data_files - list of csv files to be read\n","  '''\n","  for f in data_files:\n","    tmp_df = pd.read_csv(os.path.join(data_path, f))\n","    total_images = len(tmp_df)\n","    if total_images >= temporal_length:\n","      num_samples = int((total_images - temporal_length)/temporal_stride) + 1\n","      # print('num of samples from vid seq-{}: {}'.format(f, num_samples))\n","    else:\n","      # print('num of frames is less than temporal length; hence discarding this \\\n","      #       file-{}'.format(f))\n","      continue\n","\n","    samples = deque()\n","    labels = deque()\n","\n","    for index, row in tmp_df.iterrows():\n","      samples.append('/content/drive/My Drive' + row['filename'][30:])\n","      labels.append(int(row['Flames']))\n","      if len(samples) == temporal_length:\n","        to_delete = False\n","        if labels.count(labels[0]) != len(labels):\n","          to_delete = True\n","        samples_c = copy.deepcopy(samples)\n","        for t in range(temporal_stride):\n","          samples.popleft()\n","          labels.popleft()\n","        if to_delete: continue\n","        yield samples_c, labels[0]\n","\n","def load_samples(CSV_folder, temporal_stride, temporal_length):\n","  data_path = os.path.join('csv', CSV_folder)\n","  data_files = os.listdir(data_path)\n","  file_gen = file_generator(data_path, data_files, temporal_stride, temporal_length)\n","  iterator = True\n","  data_list = []\n","\n","  while iterator:\n","    try:\n","      x, y = next(file_gen)\n","      x = list(x)\n","      data_list.append([x, y])\n","    except Exception as e:\n","      # print('Exception: ', e)\n","      iterator = False\n","      # print('end of data generator ')\n","  return data_list\n","\n","def to_weight(train_data):\n","  # putting generated labels into a list\n","  training_labels = []\n","  for sample in range(len(train_data)):\n","    training_labels.append(train_data[sample][1])\n","\n","  weights_sklearn = compute_class_weight(class_weight='balanced', \n","                                        classes=np.unique(np.array(training_labels)),\n","                                        y=np.array(training_labels))\n","  weights = {0: weights_sklearn[0], 1: weights_sklearn[1]}\n","  return weights\n","\n","class DataGenerator(Sequence):\n","\n","    def __init__(self, data, batch_size, shuffle_data, aug):\n","        self.num_samples = len(data)\n","        self.data = shuffle(data) if shuffle_data else data\n","        self.batch_size = batch_size\n","        self.aug = aug        \n","        self.additional_targets = {[f'image{i}' for i in range(sequence_length-1)][j]:'image' for j in range(sequence_length-1)}\n","\n","    def __len__(self):\n","        return math.ceil(len(self.data) / self.batch_size)\n","\n","    def __getitem__(self, idx):\n","        #print('starting index: ', idx * self.batch_size)\n","        batch_samples = self.data[idx * self.batch_size:(idx + 1) * self.batch_size]\n","        X_train = []\n","        y_train = []\n","        for batch_sample in batch_samples:\n","            x = batch_sample[0]   # Load image (X)\n","            y = batch_sample[1]   # Read label (y)\n","            temp_data_list = []\n","            for img_name in x:\n","                try:\n","                    img = cv2.imread(img_name)\n","                    img = cv2.resize(img, (224,224))\n","                    temp_data_list.append(img[:,:, ::-1])\n","                except Exception as e:\n","                    print(e)\n","                    print('error reading file: ', img_name)\n","            if self.aug:\n","                temp_data_list = self.__totransform__(temp_data_list)\n","            # Add example to arrays\n","            X_train.append(temp_data_list)\n","            y_train.append(y)\n","        # Make sure they're numpy arrays (as opposed to lists)\n","        X_train = np.array(X_train)\n","        y_train = np.array(y_train)\n","        return X_train, y_train\n","   \n","    def __totransform__(self, list_of_frames):\n","\n","        transform = A.Compose([   \n","            A.HorizontalFlip(p=0.5),\n","            A.OneOf(\n","              [\n","                A.Blur(p=0.01, blur_limit=(3, 7)),\n","                A.MedianBlur(p=0.01, blur_limit=(3, 7)),\n","                A.MotionBlur(p=0.01, blur_limit=(3, 7)),\n","                A.GaussianBlur(p=0.01, blur_limit=(3, 7), sigma_limit=(0.0, 0)),\n","                #A.ZoomBlur(p=0.01, max_factor=(1.0, 1.12), step_factor=(0.01, 0.03)),\n","                #A.Defocus(p=0.01, radius=(1, 4), alias_blur=(0.1, 0.5)),\n","                A.RingingOvershoot(p=0.01, blur_limit=(7, 15), cutoff=(0.7, 1.57)),\n","                A.Downscale(p=0.01, scale_min=0.8, scale_max=0.99),\n","                A.ImageCompression(p=0.01, quality_lower=80, quality_upper=100,\n","                                    compression_type=0),\n","                A.JpegCompression(p=0.01, quality_lower=80, quality_upper=100),\n","                A.GaussNoise(p=0.01, var_limit=(10, 50), per_channel=True, mean=0.0),\n","                A.MultiplicativeNoise(p=0.01, multiplier=(0.9, 1.1), \n","                                        per_channel=True, elementwise=True),\n","                # A.CLAHE(p=0.01, clip_limit=(1,4), tile_grid_size=(8, 8)),\n","                # A.Sharpen(p=0.01, alpha=(0.2, 0.5), lightness=(0.5, 1.0)),\n","                # A.UnsharpMask(p=0.01, blur_limit=(3, 7), sigma_limit=(0.0, 0.0),\n","                #                 alpha=(0.2, 0.5), threshold=10),\n","                # A.Emboss(p=0.01, alpha=(0.2, 0.5), strength=(0.2, 0.7)),\n","                # A.RandomBrightness(p=0.01, limit=(-0.2, 0.2)),\n","                # A.RandomContrast(p=0.01, limit=(-0.2, 0.2)),\n","                # A.RandomBrightnessContrast(p=0.01, brightness_limit=(-0.2, 0.2),\n","                #                             contrast_limit=(-0.2, 0.2), \n","                #                             brightness_by_max=True),\n","                # A.ISONoise(p=0.01, intensity=(0.1, 0.5), color_shift=(0.01, 0.05)),\n","                # A.Equalize(p=0.01, mode='cv', by_channels=False),             \n","                # A.FancyPCA(p=0.01, alpha=0.1),\n","                # A.RGBShift(p=0.01, r_shift_limit=(-20, 20), \n","                #             g_shift_limit=(-20, 20), b_shift_limit=(-20, 20)),\n","                # A.RandomGamma(p=0.01, gamma_limit=(80, 120), eps=None),\n","                # A.RandomToneCurve(p=0.01, scale=0.1),\n","                # A.SafeRotate(p=0.01, limit=(-90, 90), interpolation=0, \n","                #               border_mode=0, value=(0, 0, 0), mask_value=None),\n","                # A.OpticalDistortion(p=0.01, distort_limit=(-0.3, 0.3),\n","                #                       shift_limit=(-0.05, 0.05), interpolation=0,\n","                #                       border_mode=0, value=(0, 0, 0), mask_value=None),\n","                # A.GridDistortion(p=0.01, num_steps=5, distort_limit=(-0.3, 0.3),\n","                #                   interpolation=0, border_mode=0, value=(0, 0, 0),\n","                #                   mask_value=None, normalized=False),\n","                # A.Perspective(p=0.01, scale=(0.05, 0.1), keep_size=0, pad_mode=0,\n","                #                 pad_val=(0, 0, 0), mask_pad_val=0, fit_output=0, \n","                #                 interpolation=0),\n","                # A.PiecewiseAffine(p=0.01, scale=(0.03, 0.05), nb_rows=(4, 4), \n","                #                     nb_cols=(4, 4), interpolation=0,\n","                #                     mask_interpolation=0, cval=0, cval_mask=0,\n","                #                     mode='constant', absolute_scale=0, \n","                #                     keypoints_threshold=0.01),\n","                # A.RandomCropFromBorders(p=0.01, crop_left=0.1, crop_right=0.1, \n","                #                           crop_top=0.1, crop_bottom=0.1),\n","                # A.CoarseDropout(p=0.01, max_holes=8, max_height=8, max_width=8, \n","                #                   min_holes=8, min_height=8, min_width=8, \n","                #                   fill_value=(0, 0, 0), mask_fill_value=None),\n","                # A.PixelDropout(p=0.01, dropout_prob=0.01, per_channel=0, \n","                #                 drop_value=(0, 0, 0), mask_drop_value=None),\n","                # A.RandomFog(p=0.01, fog_coef_lower=0.2, fog_coef_upper=0.2, \n","                #               alpha_coef=0.08),\n","                # A.RandomSnow(p=0.01, snow_point_lower=0.1, snow_point_upper=0.1, \n","                #               brightness_coeff=2),\n","                # A.RandomRain(p=0.01, slant_lower=-10, slant_upper=10, \n","                #               drop_length=20, drop_width=1, drop_color=(0, 0, 0),\n","                #               blur_value=3, brightness_coefficient=0.7, rain_type=None),\n","                # A.Spatter(p=0.01, mean=(0.65, 0.65), std=(0.3, 0.3), \n","                #             gauss_sigma=(2.0, 2.0), intensity=(0.6, 0.6), \n","                #             cutout_threshold=(0.68, 0.68), mode=['rain']),\n","                # A.Spatter(p=0.01, mean=(0.65, 0.65), std=(0.3, 0.3), \n","                #             gauss_sigma=(2.0, 2.0), intensity=(0.6, 0.6), \n","                #             cutout_threshold=(0.68, 0.68), mode=['mud']),\n","              ], p=0.8),\n","        ], additional_targets=self.additional_targets)\n","\n","        transformed = transform(image=list_of_frames[0], \n","                                image0=list_of_frames[1], \n","                                image1=list_of_frames[2],\n","                                image2=list_of_frames[3],\n","                                image3=list_of_frames[4],\n","                                image4=list_of_frames[5],\n","                                image5=list_of_frames[6],\n","                                image6=list_of_frames[7]  )\n","        \n","        return  [   cv2.resize(transformed['image'], (224,224)),\n","                    cv2.resize(transformed['image0'], (224,224)),\n","                    cv2.resize(transformed['image1'], (224,224)),\n","                    cv2.resize(transformed['image2'], (224,224)),\n","                    cv2.resize(transformed['image3'], (224,224)),\n","                    cv2.resize(transformed['image4'], (224,224)),\n","                    cv2.resize(transformed['image5'], (224,224)),\n","                    cv2.resize(transformed['image6'], (224,224))   ]\n","\n","fit_results = []\n","evaluate_results = []\n","\n","for count in range(1, 6):\n","    train_data = load_samples(CSV_folder='Train/urban/KFold_long-range/fold'\\\n","                                + str(count), temporal_stride=sequence_stride,\n","                            temporal_length=sequence_length)\n","    test_data = load_samples(CSV_folder='Test/urban/KFold_long-range/fold'\\\n","                            + str(count), temporal_stride=sequence_stride,\n","                            temporal_length=sequence_length)\n","    val_data = load_samples(CSV_folder='Validation/urban/KFold_long-range/fold'\\\n","                           + str(count), temporal_stride=sequence_stride,\n","                          temporal_length=sequence_length)\n","    \n","    weights = to_weight(train_data)\n","\n","    train_gen = DataGenerator(data=train_data, batch_size=batch_size, \n","                                shuffle_data=True, aug=True)\n","    test_gen = DataGenerator(data=test_data, batch_size=batch_size, \n","                            shuffle_data=False, aug=False)\n","    val_gen = DataGenerator(data=val_data, batch_size=batch_size, \n","                            shuffle_data=True, aug=False)\n","\n","    model = new_model\n","    model.compile(loss='binary_crossentropy',\n","                    optimizer=SGD(), metrics=['accuracy'])\n","    \n","    cs = 'case8_seq8'\n","    \n","    my_callbacks = [\n","        keras.callbacks.EarlyStopping(monitor='val_loss', verbose=1, patience=5,\n","                                    mode='auto', restore_best_weights=True),\n","        keras.callbacks.ModelCheckpoint(\n","            'models/urban/long-range/EfficientDet/new_sequence_lengths/8temporal_length_4temporalstride/' + cs + '_best_model' + str(count) + '.h5',\n","            monitor='val_loss', verbose=1, save_best_only=True, mode='auto'),\n","        keras.callbacks.TensorBoard(log_dir='models/urban/long-range/EfficientDet/new_sequence_lengths/8temporal_length_4temporalstride/' + cs + '_tensorboard' + str(count)),\n","        keras.callbacks.CSVLogger(\n","            'models/urban/long-range/EfficientDet/new_sequence_lengths/8temporal_length_4temporalstride/' + cs + '_epochs_results' + str(count) + '.csv',\n","            separator=\",\", append=False),\n","    ]\n","\n","    print(\"\\n\\n\" + cs + \" - STARTING FIT \" + str(count) + \" ...\\n\\n\")\n","\n","    model.fit(train_gen, epochs=50, validation_data=val_gen, callbacks=my_callbacks,\n","            class_weight=weights, use_multiprocessing=True, workers=4)"],"metadata":{"id":"Ae2sQp28q-QP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FcrO3QbOvdYP"},"source":["# Evaluate the model with new temporal length and temporal stride"]},{"cell_type":"code","source":["# tensorflow version must be the 2.6.2 and keras version must be 2.6.0.\n","!pip install tensorflow==2.6.2\n","%tensorflow_version 2.6.2\n","\n","# !!!!!!!!!!!!!! AFTER EXECUTING THIS CELL, RESTART THE RUNTIME !!!!!!!!!!!!!!!!"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RnfbBe6KIxlf","executionInfo":{"status":"ok","timestamp":1677960228472,"user_tz":-60,"elapsed":86825,"user":{"displayName":"DANIELE SILVITELLI","userId":"06101420645295177517"}},"outputId":"a01c3a4c-d33f-49bd-9977-d5d629440294"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow==2.6.2\n","  Downloading tensorflow-2.6.2-cp38-cp38-manylinux2010_x86_64.whl (458.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m458.4/458.4 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard<2.7,>=2.6.0\n","  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.6.2) (3.1.0)\n","Collecting absl-py~=0.10\n","  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.6.2) (1.6.3)\n","Collecting numpy~=1.19.2\n","  Downloading numpy-1.19.5-cp38-cp38-manylinux2010_x86_64.whl (14.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting termcolor~=1.1.0\n","  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting flatbuffers~=1.12.0\n","  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.6.2) (1.15.0)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.6.2) (3.3.0)\n","Collecting keras<2.7,>=2.6.0\n","  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.6.2) (3.19.6)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.6.2) (0.38.4)\n","Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.6.2) (1.51.3)\n","Collecting tensorflow-estimator<2.7,>=2.6.0\n","  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.9/462.9 KB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.6.2) (0.2.0)\n","Collecting typing-extensions~=3.7.4\n","  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n","Collecting clang~=5.0\n","  Downloading clang-5.0.tar.gz (30 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting keras-preprocessing~=1.1.2\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting wrapt~=1.12.1\n","  Downloading wrapt-1.12.1.tar.gz (27 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.6.2) (0.4.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (3.4.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (57.4.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (0.4.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (2.25.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (0.6.1)\n","Collecting google-auth<2,>=1.6.3\n","  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.9/152.9 KB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (2.2.3)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (1.8.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (4.9)\n","Collecting cachetools<5.0,>=2.0.0\n","  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (6.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (1.26.14)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (2022.12.7)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=0.11.15->tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (2.1.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (3.15.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow==2.6.2) (3.2.2)\n","Building wheels for collected packages: clang, termcolor, wrapt\n","  Building wheel for clang (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30694 sha256=aeeaff5773a71ed86cc2ae38b5962e891019160b5d3a39b8d866d13db4f8aa2e\n","  Stored in directory: /root/.cache/pip/wheels/f1/60/77/22b9b5887bd47801796a856f47650d9789c74dc3161a26d608\n","  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4849 sha256=acfba9d999aa93686adec71f7852fe2f312e44fab55fc4a7eceb2c55e48f7d4f\n","  Stored in directory: /root/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n","  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wrapt: filename=wrapt-1.12.1-cp38-cp38-linux_x86_64.whl size=78584 sha256=92f4d2d0de205c91f13e79212b45cd70dd71de4073b5a0bbc2b09917a653a57e\n","  Stored in directory: /root/.cache/pip/wheels/5f/fd/9e/b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n","Successfully built clang termcolor wrapt\n","Installing collected packages: wrapt, typing-extensions, termcolor, tensorflow-estimator, keras, flatbuffers, clang, numpy, cachetools, absl-py, keras-preprocessing, google-auth, tensorboard, tensorflow\n","  Attempting uninstall: wrapt\n","    Found existing installation: wrapt 1.15.0\n","    Uninstalling wrapt-1.15.0:\n","      Successfully uninstalled wrapt-1.15.0\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.5.0\n","    Uninstalling typing_extensions-4.5.0:\n","      Successfully uninstalled typing_extensions-4.5.0\n","  Attempting uninstall: termcolor\n","    Found existing installation: termcolor 2.2.0\n","    Uninstalling termcolor-2.2.0:\n","      Successfully uninstalled termcolor-2.2.0\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.11.0\n","    Uninstalling tensorflow-estimator-2.11.0:\n","      Successfully uninstalled tensorflow-estimator-2.11.0\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.11.0\n","    Uninstalling keras-2.11.0:\n","      Successfully uninstalled keras-2.11.0\n","  Attempting uninstall: flatbuffers\n","    Found existing installation: flatbuffers 23.1.21\n","    Uninstalling flatbuffers-23.1.21:\n","      Successfully uninstalled flatbuffers-23.1.21\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.22.4\n","    Uninstalling numpy-1.22.4:\n","      Successfully uninstalled numpy-1.22.4\n","  Attempting uninstall: cachetools\n","    Found existing installation: cachetools 5.3.0\n","    Uninstalling cachetools-5.3.0:\n","      Successfully uninstalled cachetools-5.3.0\n","  Attempting uninstall: absl-py\n","    Found existing installation: absl-py 1.4.0\n","    Uninstalling absl-py-1.4.0:\n","      Successfully uninstalled absl-py-1.4.0\n","  Attempting uninstall: google-auth\n","    Found existing installation: google-auth 2.16.1\n","    Uninstalling google-auth-2.16.1:\n","      Successfully uninstalled google-auth-2.16.1\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.11.2\n","    Uninstalling tensorboard-2.11.2:\n","      Successfully uninstalled tensorboard-2.11.2\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.11.0\n","    Uninstalling tensorflow-2.11.0:\n","      Successfully uninstalled tensorflow-2.11.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","xarray 2022.12.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n","xarray-einstats 0.5.1 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n","pydantic 1.10.5 requires typing-extensions>=4.2.0, but you have typing-extensions 3.7.4.3 which is incompatible.\n","jaxlib 0.4.4+cuda11.cudnn82 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n","jax 0.4.4 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n","google-api-core 2.11.0 requires google-auth<3.0dev,>=2.14.1, but you have google-auth 1.35.0 which is incompatible.\n","cmdstanpy 1.1.0 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n","bokeh 2.4.3 requires typing-extensions>=3.10.0, but you have typing-extensions 3.7.4.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed absl-py-0.15.0 cachetools-4.2.4 clang-5.0 flatbuffers-1.12 google-auth-1.35.0 keras-2.6.0 keras-preprocessing-1.1.2 numpy-1.19.5 tensorboard-2.6.0 tensorflow-2.6.2 tensorflow-estimator-2.6.0 termcolor-1.1.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n","Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"]}]},{"cell_type":"code","source":["import tensorflow\n","print(tensorflow.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"42anqyrRVIhb","executionInfo":{"status":"ok","timestamp":1677964385293,"user_tz":-60,"elapsed":5682,"user":{"displayName":"DANIELE SILVITELLI","userId":"06101420645295177517"}},"outputId":"b1ac34cf-5b5d-462e-81e6-75d0bbe1782c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.6.2\n"]}]},{"cell_type":"code","source":["from tensorflow import keras\n","print(keras.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gkoSsQFLVXu5","executionInfo":{"status":"ok","timestamp":1677960265685,"user_tz":-60,"elapsed":939,"user":{"displayName":"DANIELE SILVITELLI","userId":"06101420645295177517"}},"outputId":"21709609-db31-4a0a-d59e-05f6c40d1776"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.6.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QJVCuf_FAXwc"},"outputs":[],"source":["import os\n","import cv2\n","import math\n","import copy\n","import random\n","import numpy as np\n","import pandas as pd\n","from tensorflow import keras\n","from collections import deque\n","import matplotlib.pyplot as plt\n","from sklearn.utils import shuffle\n","from keras.models import load_model\n","from tensorflow.keras.utils import Sequence\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","\n","\n","sequence_length = 8\n","sequence_stride = 4\n","batch_size      = 16\n","\n","def file_generator(data_path, data_files, temporal_stride, temporal_length):\n","  '''\n","  data_files - list of csv files to be read\n","  '''\n","  for f in data_files:\n","    tmp_df = pd.read_csv(os.path.join(data_path, f))\n","    total_images = len(tmp_df)\n","    if total_images >= temporal_length:\n","      num_samples = int((total_images - temporal_length)/temporal_stride) + 1\n","      #print('num of samples from vid seq-{}: {}'.format(f, num_samples))\n","    else:\n","      #print('num of frames is less than temporal length; hence discarding this \\\n","      #      file-{}'.format(f))\n","      continue\n","\n","    samples = deque()\n","    labels = deque()\n","\n","    for index, row in tmp_df.iterrows():\n","      samples.append('/content/drive/My Drive' + row['filename'][30:])\n","      labels.append(int(row['Flames']))\n","      if len(samples) == temporal_length:\n","        to_delete = False\n","        if labels.count(labels[0]) != len(labels):\n","          to_delete = True\n","        samples_c = copy.deepcopy(samples)\n","        for t in range(temporal_stride):\n","          samples.popleft()\n","          labels.popleft()\n","        if to_delete: continue\n","        yield samples_c, labels[0]\n","\n","def load_samples(CSV_folder, temporal_stride, temporal_length):\n","  data_path = os.path.join('csv', CSV_folder)\n","  data_files = os.listdir(data_path)\n","  file_gen = file_generator(data_path, data_files, temporal_stride, temporal_length)\n","  iterator = True\n","  data_list = []\n","\n","  while iterator:\n","    try:\n","      x, y = next(file_gen)\n","      x = list(x)\n","      data_list.append([x, y])\n","    except Exception as e:\n","      #print('Exception: ', e)\n","      iterator = False\n","      #print('end of data generator ')\n","  return data_list\n","\n","class DataGenerator(Sequence):\n","\n","    def __init__(self, data, batch_size, shuffle_data, aug):\n","        self.num_samples = len(data)\n","        self.data = shuffle(data) if shuffle_data else data\n","        self.batch_size = batch_size\n","        self.aug = aug        \n","        self.additional_targets = {[f'image{i}' for i in range(sequence_length-1)][j]:'image' for j in range(sequence_length-1)}\n","\n","    def __len__(self):\n","        return math.ceil(len(self.data) / self.batch_size)\n","\n","    def __getitem__(self, idx):\n","        #print('starting index: ', idx * self.batch_size)\n","        batch_samples = self.data[idx * self.batch_size:(idx + 1) * self.batch_size]\n","        X_train = []\n","        y_train = []\n","        for batch_sample in batch_samples:\n","            x = batch_sample[0]   # Load image (X)\n","            y = batch_sample[1]   # Read label (y)\n","            temp_data_list = []\n","            for img_name in x:\n","                try:\n","                    img = cv2.imread(img_name)\n","                    img = cv2.resize(img, (224,224))\n","                    temp_data_list.append(img[:,:, ::-1])\n","                except Exception as e:\n","                    print(e)\n","                    print('error reading file: ', img_name)\n","            # if self.aug:\n","            #     temp_data_list = self.__totransform__(temp_data_list)\n","            # Add example to arrays\n","            X_train.append(temp_data_list)\n","            y_train.append(y)\n","        # Make sure they're numpy arrays (as opposed to lists)\n","        X_train = np.array(X_train)\n","        y_train = np.array(y_train)\n","        return X_train, y_train\n","\n","test_data = load_samples(CSV_folder='Test/urban/KFold_long-range/fold2', \n","                            temporal_stride=sequence_stride,\n","                            temporal_length=sequence_length)\n","\n","test_gen = DataGenerator(data=test_data, batch_size=batch_size, \n","                         shuffle_data=False, aug=False)\n","\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","\n","def plot_cm(y, pred):\n","  p = []\n","  for i in pred:\n","    p.append(round(list(i)[0]))\n","  p = np.array(p)\n","  y = np.array(y)\n","  cm = confusion_matrix(y, p)\n","  disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n","  print('Accuracy: %.3f' % (y==p).mean())\n","  disp.plot()\n","  plt.title('Accuracy: %.3f' % (y==p).mean())\n","  plt.show()\n","\n","model = load_model('models/urban/long-range/EfficientDet/new_sequence_lengths/8temporal_length_4temporalstride/case8_seq8_best_model2.h5')\n","\n","test_labels = []\n","for test in range(len(test_data)):\n","  test_labels.append(test_data[test][1])\n","\n","pred = model.predict(test_gen)\n","plot_cm(y=test_labels, pred=list(pred))"]}],"metadata":{"colab":{"collapsed_sections":["JARIZwZx-a7X","RKidESlOdoGe","FcrO3QbOvdYP"],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}