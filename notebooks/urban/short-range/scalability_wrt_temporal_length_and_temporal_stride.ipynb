{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"AstS2QF9SN4L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678810371610,"user_tz":-60,"elapsed":28316,"user":{"displayName":"DANIELE SILVITELLI","userId":"06101420645295177517"}},"outputId":"8caaf70f-9768-4a47-fa31-61ea3794009a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eXKbFIh2SZ4X"},"outputs":[],"source":["import os\n","os.chdir('/content/drive/My Drive/Tesi')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4lfaOnjgih_B"},"outputs":[],"source":["import os\n","import cv2\n","import math\n","import copy\n","import random\n","import numpy as np\n","import pandas as pd\n","import albumentations as A\n","from tensorflow import keras\n","from collections import deque\n","import matplotlib.pyplot as plt\n","from sklearn.utils import shuffle\n","from keras.models import load_model\n","from tensorflow.keras.utils import Sequence\n","from sklearn.utils.class_weight import compute_class_weight\n","from tensorflow.keras.optimizers import Adam\n","\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","source":["sequence_length = 8\n","sequence_stride = 4\n","batch_size      = 16"],"metadata":{"id":"w-zgb7iW5rb3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Creation of the model with new temporal length and temporal stride"],"metadata":{"id":"rm-SbsyBeUrE"}},{"cell_type":"code","source":["from keras import Model\n","from keras.layers import TimeDistributed, Input\n","\n","mnv2 = load_model('models/urban/short-range/MobileNetV2/case14/case14_best_model5.h5')\n","\n","input_layer = Input(shape=(sequence_length, 224, 224, 3))\n","x = TimeDistributed(mnv2.layers[1].layer)(input_layer)\n","x = mnv2.layers[2](x)\n","x = mnv2.layers[3](x)\n","x = mnv2.layers[4](x)\n","\n","new_model = Model(inputs=input_layer, outputs=x)\n","new_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YHgbLLiToS9b","executionInfo":{"status":"ok","timestamp":1678810526046,"user_tz":-60,"elapsed":6408,"user":{"displayName":"DANIELE SILVITELLI","userId":"06101420645295177517"}},"outputId":"caf12d00-2f75-4785-d76f-be2fedee22ec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 8, 224, 224, 3)]  0         \n","                                                                 \n"," time_distributed_1 (TimeDis  (None, 8, 1280)          2257984   \n"," tributed)                                                       \n","                                                                 \n"," lstm_1 (LSTM)               (None, 100)               552400    \n","                                                                 \n"," dropout_1 (Dropout)         (None, 100)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 101       \n","                                                                 \n","=================================================================\n","Total params: 2,810,485\n","Trainable params: 2,776,373\n","Non-trainable params: 34,112\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["# Train the model with new temporal length and temporal stride"],"metadata":{"id":"RKidESlOdoGe"}},{"cell_type":"code","source":["def file_generator(data_path, data_files, temporal_stride, temporal_length):\n","  '''\n","  data_files - list of csv files to be read\n","  '''\n","  for f in data_files:\n","    tmp_df = pd.read_csv(os.path.join(data_path, f))\n","    total_images = len(tmp_df)\n","    if total_images >= temporal_length:\n","      num_samples = int((total_images - temporal_length)/temporal_stride) + 1\n","      # print('num of samples from vid seq-{}: {}'.format(f, num_samples))\n","    else:\n","      # print('num of frames is less than temporal length; hence discarding this \\\n","      #       file-{}'.format(f))\n","      continue\n","\n","    samples = deque()\n","    labels = deque()\n","\n","    for index, row in tmp_df.iterrows():\n","      samples.append('/content/drive/My Drive' + row['filename'][30:])\n","      labels.append(int(row['Flames']))\n","      if len(samples) == temporal_length:\n","        to_delete = False\n","        if labels.count(labels[0]) != len(labels):\n","          to_delete = True\n","        samples_c = copy.deepcopy(samples)\n","        for t in range(temporal_stride):\n","          samples.popleft()\n","          labels.popleft()\n","        if to_delete: continue\n","        yield samples_c, labels[0]\n","\n","def load_samples(CSV_folder, temporal_stride, temporal_length):\n","  data_path = os.path.join('csv', CSV_folder)\n","  data_files = os.listdir(data_path)\n","  file_gen = file_generator(data_path, data_files, temporal_stride, temporal_length)\n","  iterator = True\n","  data_list = []\n","\n","  while iterator:\n","    try:\n","      x, y = next(file_gen)\n","      x = list(x)\n","      data_list.append([x, y])\n","    except Exception as e:\n","      # print('Exception: ', e)\n","      iterator = False\n","      # print('end of data generator ')\n","  return data_list\n","\n","def to_weight(train_data):\n","  # putting generated labels into a list\n","  training_labels = []\n","  for sample in range(len(train_data)):\n","    training_labels.append(train_data[sample][1])\n","\n","  weights_sklearn = compute_class_weight(class_weight='balanced', \n","                                        classes=np.unique(np.array(training_labels)),\n","                                        y=np.array(training_labels))\n","  weights = {0: weights_sklearn[0], 1: weights_sklearn[1]}\n","  return weights\n","\n","class DataGenerator(Sequence):\n","\n","    def __init__(self, data, batch_size, shuffle_data, aug):\n","        self.num_samples = len(data)\n","        self.data = shuffle(data) if shuffle_data else data\n","        self.batch_size = batch_size\n","        self.aug = aug        \n","        self.additional_targets = {[f'image{i}' for i in range(sequence_length-1)][j]:'image' for j in range(sequence_length-1)}\n","\n","    def __len__(self):\n","        return math.ceil(len(self.data) / self.batch_size)\n","\n","    def __getitem__(self, idx):\n","        #print('starting index: ', idx * self.batch_size)\n","        batch_samples = self.data[idx * self.batch_size:(idx + 1) * self.batch_size]\n","        X_train = []\n","        y_train = []\n","        for batch_sample in batch_samples:\n","            x = batch_sample[0]   # Load image (X)\n","            y = batch_sample[1]   # Read label (y)\n","            temp_data_list = []\n","            for img_name in x:\n","                try:\n","                    img = cv2.imread(img_name)\n","                    img = cv2.resize(img, (224,224))\n","                    temp_data_list.append(img[:,:, ::-1])\n","                except Exception as e:\n","                    print(e)\n","                    print('error reading file: ', img_name)\n","            if self.aug:\n","                temp_data_list = self.__totransform__(temp_data_list)\n","            # Add example to arrays\n","            X_train.append(temp_data_list)\n","            y_train.append(y)\n","        # Make sure they're numpy arrays (as opposed to lists)\n","        X_train = np.array(X_train)\n","        y_train = np.array(y_train)\n","        return X_train, y_train\n","   \n","    def __totransform__(self, list_of_frames):\n","\n","        transform = A.Compose([   \n","            A.HorizontalFlip(p=0.5),\n","            A.OneOf(\n","              [\n","                A.Blur(p=0.01, blur_limit=(3, 7)),\n","                A.MedianBlur(p=0.01, blur_limit=(3, 7)),\n","                A.MotionBlur(p=0.01, blur_limit=(3, 7)),\n","                A.GaussianBlur(p=0.01, blur_limit=(3, 7), sigma_limit=(0.0, 0)),\n","                #A.ZoomBlur(p=0.01, max_factor=(1.0, 1.12), step_factor=(0.01, 0.03)),\n","                #A.Defocus(p=0.01, radius=(1, 4), alias_blur=(0.1, 0.5)),\n","                A.RingingOvershoot(p=0.01, blur_limit=(7, 15), cutoff=(0.7, 1.57)),\n","                A.Downscale(p=0.01, scale_min=0.8, scale_max=0.99),\n","                A.ImageCompression(p=0.01, quality_lower=80, quality_upper=100,\n","                                    compression_type=0),\n","                A.JpegCompression(p=0.01, quality_lower=80, quality_upper=100),\n","                A.GaussNoise(p=0.01, var_limit=(10, 50), per_channel=True, mean=0.0),\n","                A.MultiplicativeNoise(p=0.01, multiplier=(0.9, 1.1), \n","                                        per_channel=True, elementwise=True),\n","                # A.CLAHE(p=0.01, clip_limit=(1,4), tile_grid_size=(8, 8)),\n","                # A.Sharpen(p=0.01, alpha=(0.2, 0.5), lightness=(0.5, 1.0)),\n","                # A.UnsharpMask(p=0.01, blur_limit=(3, 7), sigma_limit=(0.0, 0.0),\n","                #                 alpha=(0.2, 0.5), threshold=10),\n","                # A.Emboss(p=0.01, alpha=(0.2, 0.5), strength=(0.2, 0.7)),\n","                # A.RandomBrightness(p=0.01, limit=(-0.2, 0.2)),\n","                # A.RandomContrast(p=0.01, limit=(-0.2, 0.2)),\n","                # A.RandomBrightnessContrast(p=0.01, brightness_limit=(-0.2, 0.2),\n","                #                             contrast_limit=(-0.2, 0.2), \n","                #                             brightness_by_max=True),\n","                # A.ISONoise(p=0.01, intensity=(0.1, 0.5), color_shift=(0.01, 0.05)),\n","                # A.Equalize(p=0.01, mode='cv', by_channels=False),             \n","                # A.FancyPCA(p=0.01, alpha=0.1),\n","                # A.RGBShift(p=0.01, r_shift_limit=(-20, 20), \n","                #             g_shift_limit=(-20, 20), b_shift_limit=(-20, 20)),\n","                # A.RandomGamma(p=0.01, gamma_limit=(80, 120), eps=None),\n","                # A.RandomToneCurve(p=0.01, scale=0.1),\n","                # A.SafeRotate(p=0.01, limit=(-90, 90), interpolation=0, \n","                #               border_mode=0, value=(0, 0, 0), mask_value=None),\n","                # A.OpticalDistortion(p=0.01, distort_limit=(-0.3, 0.3),\n","                #                       shift_limit=(-0.05, 0.05), interpolation=0,\n","                #                       border_mode=0, value=(0, 0, 0), mask_value=None),\n","                # A.GridDistortion(p=0.01, num_steps=5, distort_limit=(-0.3, 0.3),\n","                #                   interpolation=0, border_mode=0, value=(0, 0, 0),\n","                #                   mask_value=None, normalized=False),\n","                # A.Perspective(p=0.01, scale=(0.05, 0.1), keep_size=0, pad_mode=0,\n","                #                 pad_val=(0, 0, 0), mask_pad_val=0, fit_output=0, \n","                #                 interpolation=0),\n","                # A.PiecewiseAffine(p=0.01, scale=(0.03, 0.05), nb_rows=(4, 4), \n","                #                     nb_cols=(4, 4), interpolation=0,\n","                #                     mask_interpolation=0, cval=0, cval_mask=0,\n","                #                     mode='constant', absolute_scale=0, \n","                #                     keypoints_threshold=0.01),\n","                # A.RandomCropFromBorders(p=0.01, crop_left=0.1, crop_right=0.1, \n","                #                           crop_top=0.1, crop_bottom=0.1),\n","                # A.CoarseDropout(p=0.01, max_holes=8, max_height=8, max_width=8, \n","                #                   min_holes=8, min_height=8, min_width=8, \n","                #                   fill_value=(0, 0, 0), mask_fill_value=None),\n","                # A.PixelDropout(p=0.01, dropout_prob=0.01, per_channel=0, \n","                #                 drop_value=(0, 0, 0), mask_drop_value=None),\n","                # A.RandomFog(p=0.01, fog_coef_lower=0.2, fog_coef_upper=0.2, \n","                #               alpha_coef=0.08),\n","                # A.RandomSnow(p=0.01, snow_point_lower=0.1, snow_point_upper=0.1, \n","                #               brightness_coeff=2),\n","                # A.RandomRain(p=0.01, slant_lower=-10, slant_upper=10, \n","                #               drop_length=20, drop_width=1, drop_color=(0, 0, 0),\n","                #               blur_value=3, brightness_coefficient=0.7, rain_type=None),\n","                # A.Spatter(p=0.01, mean=(0.65, 0.65), std=(0.3, 0.3), \n","                #             gauss_sigma=(2.0, 2.0), intensity=(0.6, 0.6), \n","                #             cutout_threshold=(0.68, 0.68), mode=['rain']),\n","                # A.Spatter(p=0.01, mean=(0.65, 0.65), std=(0.3, 0.3), \n","                #             gauss_sigma=(2.0, 2.0), intensity=(0.6, 0.6), \n","                #             cutout_threshold=(0.68, 0.68), mode=['mud']),\n","              ], p=0.8),\n","        ], additional_targets=self.additional_targets)\n","\n","        transformed = transform(image=list_of_frames[0], \n","                                image0=list_of_frames[1], \n","                                image1=list_of_frames[2],\n","                                image2=list_of_frames[3],\n","                                image3=list_of_frames[4],\n","                                image4=list_of_frames[5],\n","                                image5=list_of_frames[6],\n","                                image6=list_of_frames[7]  )\n","        \n","        return  [   cv2.resize(transformed['image'], (224,224)),\n","                    cv2.resize(transformed['image0'], (224,224)),\n","                    cv2.resize(transformed['image1'], (224,224)),\n","                    cv2.resize(transformed['image2'], (224,224)),\n","                    cv2.resize(transformed['image3'], (224,224)),\n","                    cv2.resize(transformed['image4'], (224,224)),\n","                    cv2.resize(transformed['image5'], (224,224)),\n","                    cv2.resize(transformed['image6'], (224,224))   ]\n","\n","fit_results = []\n","evaluate_results = []\n","\n","for count in range(1, 6):\n","    train_data = load_samples(CSV_folder='Train/urban/KFold_short-range/fold'\\\n","                                + str(count), temporal_stride=sequence_stride,\n","                            temporal_length=sequence_length)\n","    test_data = load_samples(CSV_folder='Test/urban/KFold_short-range/fold'\\\n","                            + str(count), temporal_stride=sequence_stride,\n","                            temporal_length=sequence_length)\n","    val_data = load_samples(CSV_folder='Validation/urban/KFold_short-range/fold'\\\n","                           + str(count), temporal_stride=sequence_stride,\n","                          temporal_length=sequence_length)\n","    \n","    weights = to_weight(train_data)\n","\n","    train_gen = DataGenerator(data=train_data, batch_size=batch_size, \n","                                shuffle_data=True, aug=True)\n","    test_gen = DataGenerator(data=test_data, batch_size=batch_size, \n","                            shuffle_data=False, aug=False)\n","    val_gen = DataGenerator(data=val_data, batch_size=batch_size, \n","                            shuffle_data=True, aug=False)\n","\n","    model = new_model\n","    model.compile(loss='binary_crossentropy',\n","                    optimizer=Adam(0.000001), metrics=['accuracy'])\n","    \n","    cs = 'case14_seq8'\n","    \n","    my_callbacks = [\n","        keras.callbacks.EarlyStopping(monitor='val_loss', verbose=1, patience=5,\n","                                    mode='auto', restore_best_weights=True),\n","        keras.callbacks.ModelCheckpoint(\n","            'models/urban/short-range/MobileNetV2/new_sequence_lengths/8temporal_length_4temporalstride/' + cs + '_best_model' + str(count) + '.h5',\n","            monitor='val_loss', verbose=1, save_best_only=True, mode='auto'),\n","        keras.callbacks.TensorBoard(log_dir='models/urban/short-range/MobileNetV2/new_sequence_lengths/8temporal_length_4temporalstride/' + cs + '_tensorboard' + str(count)),\n","        keras.callbacks.CSVLogger(\n","            'models/urban/short-range/MobileNetV2/new_sequence_lengths/8temporal_length_4temporalstride/' + cs + '_epochs_results' + str(count) + '.csv',\n","            separator=\",\", append=False),\n","    ]\n","\n","    print(\"\\n\\n\" + cs + \" - STARTING FIT \" + str(count) + \" ...\\n\\n\")\n","\n","    model.fit(train_gen, epochs=50, validation_data=val_gen, callbacks=my_callbacks,\n","            class_weight=weights, use_multiprocessing=True, workers=4)"],"metadata":{"id":"Ae2sQp28q-QP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FcrO3QbOvdYP"},"source":["# Evaluate the model with new temporal length and temporal stride"]},{"cell_type":"code","source":["class DataGenerator(Sequence):\n","\n","    def __init__(self, data, batch_size, shuffle_data, aug):\n","        self.num_samples = len(data)\n","        self.data = shuffle(data) if shuffle_data else data\n","        self.batch_size = batch_size\n","        self.aug = aug        \n","        self.additional_targets = {[f'image{i}' for i in range(sequence_length-1)][j]:'image' for j in range(sequence_length-1)}\n","\n","    def __len__(self):\n","        return math.ceil(len(self.data) / self.batch_size)\n","\n","    def __getitem__(self, idx):\n","        #print('starting index: ', idx * self.batch_size)\n","        batch_samples = self.data[idx * self.batch_size:(idx + 1) * self.batch_size]\n","        X_train = []\n","        y_train = []\n","        for batch_sample in batch_samples:\n","            x = batch_sample[0]   # Load image (X)\n","            y = batch_sample[1]   # Read label (y)\n","            temp_data_list = []\n","            for img_name in x:\n","                try:\n","                    img = cv2.imread(img_name)\n","                    img = cv2.resize(img, (224,224))\n","                    temp_data_list.append(img[:,:, ::-1])\n","                except Exception as e:\n","                    print(e)\n","                    print('error reading file: ', img_name)\n","            # if self.aug:\n","            #     temp_data_list = self.__totransform__(temp_data_list)\n","            # Add example to arrays\n","            X_train.append(temp_data_list)\n","            y_train.append(y)\n","        # Make sure they're numpy arrays (as opposed to lists)\n","        X_train = np.array(X_train)\n","        y_train = np.array(y_train)\n","        return X_train, y_train"],"metadata":{"id":"tBg_OzLsRkm0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def file_generator(data_path, data_files, temporal_stride, temporal_length):\n","  '''\n","  data_files - list of csv files to be read\n","  '''\n","  for f in data_files:\n","    tmp_df = pd.read_csv(os.path.join(data_path, f))\n","    total_images = len(tmp_df)\n","    if total_images >= temporal_length:\n","      num_samples = int((total_images - temporal_length)/temporal_stride) + 1\n","      #print('num of samples from vid seq-{}: {}'.format(f, num_samples))\n","    else:\n","      #print('num of frames is less than temporal length; hence discarding this \\\n","      #      file-{}'.format(f))\n","      continue\n","\n","    samples = deque()\n","    labels = deque()\n","\n","    for index, row in tmp_df.iterrows():\n","      samples.append('/content/drive/My Drive' + row['filename'][30:])\n","      labels.append(int(row['Flames']))\n","      if len(samples) == temporal_length:\n","        to_delete = False\n","        if labels.count(labels[0]) != len(labels):\n","          to_delete = True\n","        samples_c = copy.deepcopy(samples)\n","        for t in range(temporal_stride):\n","          samples.popleft()\n","          labels.popleft()\n","        if to_delete: continue\n","        yield samples_c, labels[0]\n","\n","def load_samples(CSV_folder, temporal_stride, temporal_length):\n","  data_path = os.path.join('csv', CSV_folder)\n","  data_files = os.listdir(data_path)\n","  file_gen = file_generator(data_path, data_files, temporal_stride, temporal_length)\n","  iterator = True\n","  data_list = []\n","\n","  while iterator:\n","    try:\n","      x, y = next(file_gen)\n","      x = list(x)\n","      data_list.append([x, y])\n","    except Exception as e:\n","      #print('Exception: ', e)\n","      iterator = False\n","      #print('end of data generator ')\n","  return data_list\n","\n","test_data = load_samples(CSV_folder='Test/urban/KFold_short-range/fold5', \n","                            temporal_stride=sequence_stride,\n","                            temporal_length=sequence_length)\n","\n","test_gen = DataGenerator(data=test_data, batch_size=batch_size, \n","                         shuffle_data=False, aug=False)"],"metadata":{"id":"s41dZrDVFIH_"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":312},"executionInfo":{"elapsed":328020,"status":"ok","timestamp":1678012589474,"user":{"displayName":"DANIELE SILVITELLI","userId":"06101420645295177517"},"user_tz":-60},"id":"jGXq2ljafiJA","outputId":"e2805d5e-2dd5-4396-be4d-68a51801fdcd"},"outputs":[{"output_type":"stream","name":"stdout","text":["36/36 [==============================] - 283s 8s/step\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","\n","def plot_cm(y, pred):\n","  p = []\n","  for i in pred:\n","    p.append(round(list(i)[0]))\n","  p = np.array(p)\n","  y = np.array(y)\n","  cm = confusion_matrix(y, p)\n","  disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n","  disp.plot()\n","  plt.title('Accuracy: %.3f' % (y==p).mean())\n","  plt.show()\n","\n","model = load_model('models/urban/short-range/MobileNetV2/new_sequence_lengths/8temporal_length_4temporalstride/case14_seq8_best_model5.h5')\n","\n","test_labels = []\n","for test in range(len(test_data)):\n","  test_labels.append(test_data[test][1])\n","\n","pred = model.predict(test_gen)\n","plot_cm(y=test_labels, pred=list(pred))"]}],"metadata":{"colab":{"collapsed_sections":["rm-SbsyBeUrE","RKidESlOdoGe","FcrO3QbOvdYP"],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}